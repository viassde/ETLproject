{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFIDF Sentiment Analysis",
      "provenance": [],
      "collapsed_sections": [
        "9JcZjDvKOH6W",
        "0WDMQH-WvLJa"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/walraven/ETL-project/blob/master/TFIDF_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3dc477WiOqJ",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF - BAG OF WORDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbo5ZURXRzkt",
        "colab_type": "text"
      },
      "source": [
        "Bag of words implementation for text analysis is analogous to dumping all the words in a document into a bag and then counting their frequency. One major limitation to this method is that nuance, or any meaning implied by phrases and idiomatic expressions, can be difficult to infer. Consider an example document written in natural language with slightly negative, but mostly ambiguous sentiment:\n",
        "> *I can't say that I'm very satisfied with this item. The best thing about it was the price. The quality is not so good, but the color is beautiful. It doesn't have all the bells and whistles, but I know it will get you by!*\n",
        "\n",
        "We can perform a rudimentary tokenization on the document:\n",
        ">*whistles, doesn't, know, so, not, best, quality, can't, beautiful, but, item, bells, good, color, say, very, price, satisfied*\n",
        "\n",
        "Given just the tokens, it is very difficult to intuitively reason whether the sentiment is positive or negative. How are we to know which words \"can't,\" \"doesn't,\" and \"not\" apply to? The phrase \"get you by\" has been lost to stopword removal. \n",
        "\n",
        "Here is another review with the same tokens:\n",
        "\n",
        ">*So, I'm satisfied with this item. About the quality: it was very good. But the thing is, I know by the price you will not get all the bells and whistles. But, it doesn't have the best color, I can't say it is that beautiful.*\n",
        "\n",
        "not\n",
        "All the same words, but the sentiment is markedly different! By training a machine-learning model, however, we can predict sentiment with a fair amount of accuracy.\n",
        "\n",
        "After tokenizing all documents, we determine term frequency and inter-document frequency for each token. A token and tf-idf vector form a feature. The features of a test dataset are used to train various machine learning models to predict sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e17BWoOfytYT",
        "colab_type": "text"
      },
      "source": [
        "## Imports and Data Fetching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC-tg_saKFhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import joblib\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn import metrics\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZaPVbISKF7u",
        "colab_type": "code",
        "outputId": "1baa1eff-c644-43cf-f7d8-bdf2960283d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#get data\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBkPuMDUut2l",
        "colab_type": "code",
        "outputId": "7e4f9724-aaf2-4252-e785-6277abdf3271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#decompress data\n",
        "!tar -xvf '/content/drive/My Drive/Data-Camp/project3/amazon_review_polarity_csv.tar.gz'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amazon_review_polarity_csv/\n",
            "amazon_review_polarity_csv/test.csv\n",
            "amazon_review_polarity_csv/train.csv\n",
            "amazon_review_polarity_csv/readme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnPgljJKzGHt",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTNTRCMsKF4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('amazon_review_polarity_csv/train.csv', names=['label', 'title', 'review'])\n",
        "test_data = pd.read_csv('amazon_review_polarity_csv/test.csv', names = ['label', 'title', 'review'])\n",
        "label_names = ['negative', 'positive']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAsz6sqMwdtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#necessary for logistic regression and random search below\n",
        "tf_idf_vectorizer = TfidfVectorizer()\n",
        "X_train_tf_idf = tf_idf_vectorizer.fit_transform(train_data.review)\n",
        "X_test_tf_idf = tf_idf_vectorizer.transform(test_data.review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQcFF0VcR1gw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "172c56ab-0bea-4c1e-c375-87a62f6dcf8b"
      },
      "source": [
        "#save this for use later\n",
        "vectorizer_filename = 'fitted_vectorizer.sav'\n",
        "joblib.dump(tf_idf_vectorizer, vectorizer_filename)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fitted_vectorizer.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2REMT5x_2jVr",
        "colab_type": "text"
      },
      "source": [
        "## Model: LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzESQn5VH4ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create model\n",
        "lr_classifier_model = LogisticRegression(solver='sag', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq8jI-d92ogL",
        "colab_type": "code",
        "outputId": "1693a777-8d64-400b-9462-097b8c319f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#train model with train data\n",
        "lr_classifier_model.fit(X_train_tf_idf, train_data.label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 40 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "convergence after 22 epochs took 198 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                   random_state=None, solver='sag', tol=0.0001, verbose=2,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U36fTq3M2osh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict with model, using test data\n",
        "lr_predicted = lr_classifier_model.predict(X_test_tf_idf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6rsTZyRXFx2",
        "colab_type": "code",
        "outputId": "2eb0544e-c8b9-4182-a3aa-3b0dffaa324e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#view the results\n",
        "print(f'accuracy : {np.mean(lr_predicted == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label , lr_predicted, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.8893175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru-UWlugdGkd",
        "colab_type": "text"
      },
      "source": [
        "##Model: NAIVE BAYES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR4xa6TYXO6h",
        "colab_type": "code",
        "outputId": "4a9a1189-827c-48d5-ab57-ee925fbf5e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb_classifier_model = Pipeline([('tfidf-vect', TfidfVectorizer()),\n",
        "                     ('clf', MultinomialNB())],\n",
        "                     verbose=True)\n",
        "nb_classifier_model.fit(train_data.review, train_data.label)\n",
        "nb_predicted = nb_classifier_model.predict(test_data.review)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] .............. (step 1 of 3) Processing vect, total= 3.3min\n",
            "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=  26.6s\n",
            "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPahrOe6a2JE",
        "colab_type": "code",
        "outputId": "3c809b0f-1675-4604-9e25-84e9b70df732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "num_reviews = 0\n",
        "num_correct = 0\n",
        "for actual, prediction in zip(test_data.label, nb_predicted):\n",
        "  num_reviews += 1\n",
        "  if actual == prediction:\n",
        "    num_correct += 1\n",
        "print(f'accuracy: {num_correct/num_reviews} :: ({num_correct}/{num_reviews})''')\n",
        "print(metrics.classification_report(test_data.label, nb_predicted, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.82834\n",
            "accuracy: 0.82909\n",
            "accuracy: 0.8288666666666666\n",
            "accuracy: 0.828535\n",
            "accuracy: 0.827396\n",
            "accuracy: 0.82657\n",
            "accuracy: 0.8261057142857143\n",
            "accuracy: 0.8256575\n",
            "accuracy: 0.8256575 :: (330263/400000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0diJmCgdSrU",
        "colab_type": "text"
      },
      "source": [
        "## Model: SUPPORT VECTOR MACHINE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkWHCJg3aKgO",
        "colab_type": "code",
        "outputId": "fbd22339-f346-4107-b413-4cd7b53f0ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "svm_classifier_model = Pipeline([('tfidf-vect', TfidfVectorizer()),\n",
        "                     ('clf', SGDClassifier(n_jobs=-1))],\n",
        "                     verbose=True)\n",
        "svm_classifier_model.fit(train_data.review, train_data.label)\n",
        "svm_predicted = svm_classifier_model.predict(test_data.review)\n",
        "print(f'accuracy : {np.mean(svm_predicted == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label, svm_predicted, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ........ (step 1 of 2) Processing tfidf-vect, total= 3.6min\n",
            "[Pipeline] ............... (step 2 of 2) Processing clf, total=  22.0s\n",
            "accuracy : 0.86563\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.87      0.87    200000\n",
            "    positive       0.87      0.86      0.87    200000\n",
            "\n",
            "    accuracy                           0.87    400000\n",
            "   macro avg       0.87      0.87      0.87    400000\n",
            "weighted avg       0.87      0.87      0.87    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGIU9usaXcCG",
        "colab_type": "text"
      },
      "source": [
        "## Model: LOGISTIC REGRESSION - *Manual Tuning*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALmA3yTi2onR",
        "colab_type": "code",
        "outputId": "17177a63-d94f-4d78-baa7-32f4c8ff572b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "lr_lbfgs_model = LogisticRegression(solver='lbfgs', tol=0.0005, verbose=2, n_jobs=-1)\n",
        "lr_lbfgs_model.fit(X_train_tf_idf, train_data.label)\n",
        "lr_lbfgs_predicted = lr_lbfgs_model.predict(X_test_tf_idf)\n",
        "print(f'accuracy : {np.mean(lr_lbfgs_predicted == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label , lr_lbfgs_predicted, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  4.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.8872875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.89      0.89    200000\n",
            "    positive       0.89      0.89      0.89    200000\n",
            "\n",
            "    accuracy                           0.89    400000\n",
            "   macro avg       0.89      0.89      0.89    400000\n",
            "weighted avg       0.89      0.89      0.89    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPT7O1tNgMTf",
        "colab_type": "text"
      },
      "source": [
        "Pretty close to the other model in terms of accuracy. There's a faster way to get a better model: Randomized Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyiC-IzvcWUJ",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection: RANDOMIZED SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9_0rFu0dXH7",
        "colab_type": "code",
        "outputId": "30591694-2b54-403d-aca1-4bb3150d8e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#with many params, use randomized search\n",
        "lr_model = LogisticRegression(n_jobs=-1)\n",
        "lr_params = dict(C=uniform(loc=0,scale=3),\n",
        "                 tol=loguniform(1e-5,1e-3),\n",
        "                 max_iter=uniform(loc=100,scale=400),\n",
        "                 solver=['sag', 'lbfgs'])\n",
        "lr_grid = RandomizedSearchCV(lr_model, lr_params,verbose=3, n_iter=10, n_jobs=8)\n",
        "lr_search = lr_grid.fit(X_train_tf_idf, train_data.label)\n",
        "print(lr_search.best_params_)\n",
        "print(lr_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  6.9min\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed: 23.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.4896280135486135,\n",
              " 'max_iter': 462.52287211168,\n",
              " 'solver': 'sag',\n",
              " 'tol': 0.0005473468337312529}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFp6EUVoQ-xs",
        "colab_type": "code",
        "outputId": "ee684b4e-b3cc-4149-e3a4-1671b2c7f4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "#make a slight tune to try to further increase accuracy\n",
        "ideal_lr_model = LogisticRegression(n_jobs=-1, C=1.48963, max_iter = 463, solver='sag', tol=0.00055)\n",
        "ideal_lr_model.fit(X_train_tf_idf, train_data.label)\n",
        "ideal_lr_predictions = ideal_lr_model.predict(X_test_tf_idf)\n",
        "print(f'accuracy : {np.mean(ideal_lr_predictions == test_data.label)}')\n",
        "print(metrics.classification_report(test_data.label , ideal_lr_predictions, target_names=label_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.88943\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.89      0.89    200000\n",
            "    positive       0.89      0.89      0.89    200000\n",
            "\n",
            "    accuracy                           0.89    400000\n",
            "   macro avg       0.89      0.89      0.89    400000\n",
            "weighted avg       0.89      0.89      0.89    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvSU4gxNe7gg",
        "colab_type": "code",
        "outputId": "b891494c-d30f-4e55-85ba-c5c8e9b66489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#this model performed even better! so we'll save it as our best log reg model\n",
        "lr_filename = 'top_lr_model.sav'\n",
        "joblib.dump(ideal_lr_model, lr_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['top_lr_model.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JcZjDvKOH6W",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection: GRID SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fBE1EmZCFw3",
        "colab_type": "code",
        "outputId": "49a989a6-3b58-446d-ee94-d8fcd7444791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#svm: alpha, tol, max_iter\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "svm_model = SGDClassifier(n_jobs=-1, early_stopping=True)\n",
        "svm_params = dict(alpha=[1e-5, 5e-4, 1e-4, 5e-3, 1e-3],\n",
        "               tol=[1e-4, 5e-3, 1e-3, 5e-2, 1e-2],\n",
        "               max_iter=[1000, 1500, 2000, 2500])\n",
        "svm_grid = GridSearchCV(estimator=svm_model, param_grid=svm_params, verbose=3, n_jobs=6)\n",
        "svm_search = svm_grid.fit(X_train_tf_idf, train_data.label)\n",
        "print(svm_search.best_params_)\n",
        "print(svm_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed: 14.3min\n",
            "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed: 26.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1e-05, 'max_iter': 2000, 'tol': 0.05}\n",
            "0.8827786111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVAiBRXvI3p7",
        "colab_type": "code",
        "outputId": "4a957dee-eee2-4865-960b-f9a86583a6ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#try again with a slightly different grid\n",
        "svm_2_params=dict(alpha=[1e-6, 5e-5, 1e-5, 5e-4, 1e-4],\n",
        "                  tol=[5e-3, 1e-3, 5e-2, 1e-2,5e-1],\n",
        "                  max_iter=[1500, 2000])\n",
        "svm_2_grid = GridSearchCV(estimator=svm_model, param_grid=svm_2_params, verbose=3, n_jobs=6)\n",
        "svm_2_search = svm_2_grid.fit(X_train_tf_idf, train_data.label)\n",
        "print(svm_2_search.best_params_)\n",
        "print(svm_2_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=6)]: Done 375 out of 375 | elapsed: 19.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1e-06, 'max_iter': 1500, 'tol': 0.5}\n",
            "0.8875144444444445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhPwNEOHnE8_",
        "colab_type": "code",
        "outputId": "b94c87a7-12c7-4196-bde0-31cf11c62857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#save this model as it is the best perfroming svm model\n",
        "svm_grid_model_fn = 'ideal_svm_grid.sav'\n",
        "joblib.dump(svm_2_grid, svm_grid_model_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ideal_svm_grid.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WDMQH-WvLJa",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection: RANDOMIZED SEARCH with SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koMClmC5lpxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_rand_model = SGDClassifier(n_jobs=-1, early_stopping=True)\n",
        "svm_rand_params = dict(alpha=loguniform(1e-7,1e-3),\n",
        "                 tol=loguniform(1e-5,1e-1),\n",
        "                 max_iter=uniform(loc=1250,scale=1750),\n",
        "                 )\n",
        "svm_rand_grid = RandomizedSearchCV(svm_rand_model, svm_rand_params, n_iter=10, n_jobs=1)\n",
        "svm_rand_search = svm_rand_grid.fit(X_train_tf_idf, train_data.label)\n",
        "print(svm_rand_search.best_params_)\n",
        "print(svm_rand_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo0UNaTHrOct",
        "colab_type": "text"
      },
      "source": [
        "This model did not have higher performance than the one produced by grid search, which is understandable as it does not test all possible models, only a randomly selected subset of them."
      ]
    }
  ]
}